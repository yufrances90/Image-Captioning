{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from torchvision import transforms\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from utils.data_loader import get_loader\n",
    "from utils.model import EncoderCNN, DecoderRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select appropriate values for the Python variables below.\n",
    "batch_size = 32          # batch size\n",
    "vocab_threshold = 5        # minimum word count threshold\n",
    "vocab_from_file = True    # if True, load existing vocab file\n",
    "embed_size = 512           # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 3             # number of training epochs\n",
    "save_every = 100             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'logs/training_log_1.txt'       # name of file with saved training loss and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_value = 2             # the maximum gradient value for clipping\n",
    "num_layers = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n",
      "Done (t=0.67s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a777285f4b646edba5e4efd60e106ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=414113.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder.load_state_dict(torch.load('./models/encoder-i-1.pkl'))\n",
    "# decoder.load_state_dict(torch.load('./models/decoder-i-1.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN(\n",
       "  (embedding): Embedding(9955, 512)\n",
       "  (lstm): LSTM(512, 512, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=9955, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the learnable parameters of the model.\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer.\n",
    "optimizer = torch.optim.ASGD(params, lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(log_file, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/12942], Loss: 8.9122, Perplexity: 7422.0067\n",
      "Epoch [1/3], Step [200/12942], Loss: 7.5872, Perplexity: 1972.7409\n",
      "Epoch [1/3], Step [300/12942], Loss: 6.7100, Perplexity: 820.55462\n",
      "Epoch [1/3], Step [400/12942], Loss: 6.2004, Perplexity: 492.9243\n",
      "Epoch [1/3], Step [500/12942], Loss: 5.7220, Perplexity: 305.5050\n",
      "Epoch [1/3], Step [600/12942], Loss: 5.5937, Perplexity: 268.7324\n",
      "Epoch [1/3], Step [700/12942], Loss: 5.4283, Perplexity: 227.7683\n",
      "Epoch [1/3], Step [800/12942], Loss: 5.1606, Perplexity: 174.2647\n",
      "Epoch [1/3], Step [900/12942], Loss: 4.8016, Perplexity: 121.7035\n",
      "Epoch [1/3], Step [1000/12942], Loss: 4.8057, Perplexity: 122.2019\n",
      "Epoch [1/3], Step [1100/12942], Loss: 5.0923, Perplexity: 162.7565\n",
      "Epoch [1/3], Step [1200/12942], Loss: 4.9793, Perplexity: 145.3778\n",
      "Epoch [1/3], Step [1300/12942], Loss: 4.2040, Perplexity: 66.95268\n",
      "Epoch [1/3], Step [1400/12942], Loss: 4.5778, Perplexity: 97.30125\n",
      "Epoch [1/3], Step [1500/12942], Loss: 4.3549, Perplexity: 77.85695\n",
      "Epoch [1/3], Step [1600/12942], Loss: 4.7407, Perplexity: 114.5170\n",
      "Epoch [1/3], Step [1700/12942], Loss: 4.2922, Perplexity: 73.12713\n",
      "Epoch [1/3], Step [1800/12942], Loss: 4.1963, Perplexity: 66.43835\n",
      "Epoch [1/3], Step [1900/12942], Loss: 4.2505, Perplexity: 70.13824\n",
      "Epoch [1/3], Step [2000/12942], Loss: 4.3825, Perplexity: 80.03804\n",
      "Epoch [1/3], Step [2100/12942], Loss: 4.1906, Perplexity: 66.06538\n",
      "Epoch [1/3], Step [2200/12942], Loss: 4.5197, Perplexity: 91.80649\n",
      "Epoch [1/3], Step [2300/12942], Loss: 4.1358, Perplexity: 62.54209\n",
      "Epoch [1/3], Step [2400/12942], Loss: 4.2719, Perplexity: 71.65413\n",
      "Epoch [1/3], Step [2500/12942], Loss: 4.1697, Perplexity: 64.69485\n",
      "Epoch [1/3], Step [2600/12942], Loss: 4.3776, Perplexity: 79.64385\n",
      "Epoch [1/3], Step [2700/12942], Loss: 4.1106, Perplexity: 60.98388\n",
      "Epoch [1/3], Step [2800/12942], Loss: 4.1367, Perplexity: 62.59313\n",
      "Epoch [1/3], Step [2900/12942], Loss: 4.0363, Perplexity: 56.61459\n",
      "Epoch [1/3], Step [3000/12942], Loss: 3.9226, Perplexity: 50.53067\n",
      "Epoch [1/3], Step [3100/12942], Loss: 4.3418, Perplexity: 76.84618\n",
      "Epoch [1/3], Step [3200/12942], Loss: 3.9706, Perplexity: 53.01621\n",
      "Epoch [1/3], Step [3300/12942], Loss: 3.9918, Perplexity: 54.15076\n",
      "Epoch [1/3], Step [3400/12942], Loss: 4.0386, Perplexity: 56.74960\n",
      "Epoch [1/3], Step [3500/12942], Loss: 3.8499, Perplexity: 46.98621\n",
      "Epoch [1/3], Step [3600/12942], Loss: 3.7746, Perplexity: 43.58084\n",
      "Epoch [1/3], Step [3700/12942], Loss: 3.6750, Perplexity: 39.44964\n",
      "Epoch [1/3], Step [3800/12942], Loss: 3.8773, Perplexity: 48.29241\n",
      "Epoch [1/3], Step [3900/12942], Loss: 3.9944, Perplexity: 54.29442\n",
      "Epoch [1/3], Step [4000/12942], Loss: 4.2275, Perplexity: 68.54907\n",
      "Epoch [1/3], Step [4100/12942], Loss: 4.0942, Perplexity: 59.99397\n",
      "Epoch [1/3], Step [4200/12942], Loss: 3.8895, Perplexity: 48.88638\n",
      "Epoch [1/3], Step [4300/12942], Loss: 3.5424, Perplexity: 34.54863\n",
      "Epoch [1/3], Step [4400/12942], Loss: 3.6541, Perplexity: 38.63293\n",
      "Epoch [1/3], Step [4500/12942], Loss: 4.1482, Perplexity: 63.32032\n",
      "Epoch [1/3], Step [4600/12942], Loss: 3.6751, Perplexity: 39.4513\n",
      "Epoch [1/3], Step [4700/12942], Loss: 3.4815, Perplexity: 32.50929\n",
      "Epoch [1/3], Step [4800/12942], Loss: 3.6362, Perplexity: 37.9479\n",
      "Epoch [1/3], Step [4900/12942], Loss: 4.3361, Perplexity: 76.41202\n",
      "Epoch [1/3], Step [5000/12942], Loss: 3.5227, Perplexity: 33.87658\n",
      "Epoch [1/3], Step [5100/12942], Loss: 3.6747, Perplexity: 39.43749\n",
      "Epoch [1/3], Step [5200/12942], Loss: 3.7115, Perplexity: 40.9155\n",
      "Epoch [1/3], Step [5300/12942], Loss: 3.8357, Perplexity: 46.3240\n",
      "Epoch [1/3], Step [5400/12942], Loss: 3.7024, Perplexity: 40.5447\n",
      "Epoch [1/3], Step [5500/12942], Loss: 3.9580, Perplexity: 52.3528\n",
      "Epoch [1/3], Step [5600/12942], Loss: 3.6825, Perplexity: 39.74725\n",
      "Epoch [1/3], Step [5700/12942], Loss: 3.5644, Perplexity: 35.3183\n",
      "Epoch [1/3], Step [5800/12942], Loss: 3.9388, Perplexity: 51.35860\n",
      "Epoch [1/3], Step [5900/12942], Loss: 3.6311, Perplexity: 37.7540\n",
      "Epoch [1/3], Step [6000/12942], Loss: 3.5808, Perplexity: 35.90134\n",
      "Epoch [1/3], Step [6100/12942], Loss: 3.7841, Perplexity: 43.9979\n",
      "Epoch [1/3], Step [6200/12942], Loss: 3.6832, Perplexity: 39.77548\n",
      "Epoch [1/3], Step [6300/12942], Loss: 4.1593, Perplexity: 64.0271\n",
      "Epoch [1/3], Step [6400/12942], Loss: 3.6470, Perplexity: 38.35995\n",
      "Epoch [1/3], Step [6500/12942], Loss: 3.4662, Perplexity: 32.0162\n",
      "Epoch [1/3], Step [6600/12942], Loss: 3.6643, Perplexity: 39.02749\n",
      "Epoch [1/3], Step [6700/12942], Loss: 3.5655, Perplexity: 35.3576\n",
      "Epoch [1/3], Step [6800/12942], Loss: 3.7808, Perplexity: 43.8489\n",
      "Epoch [1/3], Step [6900/12942], Loss: 3.9974, Perplexity: 54.4590\n",
      "Epoch [1/3], Step [7000/12942], Loss: 3.7175, Perplexity: 41.16234\n",
      "Epoch [1/3], Step [7100/12942], Loss: 3.6632, Perplexity: 38.98734\n",
      "Epoch [1/3], Step [7200/12942], Loss: 3.3882, Perplexity: 29.6128\n",
      "Epoch [1/3], Step [7300/12942], Loss: 3.1258, Perplexity: 22.7792\n",
      "Epoch [1/3], Step [7400/12942], Loss: 3.3985, Perplexity: 29.9203\n",
      "Epoch [1/3], Step [7500/12942], Loss: 3.5264, Perplexity: 34.00084\n",
      "Epoch [1/3], Step [7600/12942], Loss: 3.5709, Perplexity: 35.54913\n",
      "Epoch [1/3], Step [7700/12942], Loss: 3.7533, Perplexity: 42.6629\n",
      "Epoch [1/3], Step [7800/12942], Loss: 3.2933, Perplexity: 26.9324\n",
      "Epoch [1/3], Step [7900/12942], Loss: 3.2242, Perplexity: 25.1339\n",
      "Epoch [1/3], Step [8000/12942], Loss: 3.3236, Perplexity: 27.7607\n",
      "Epoch [1/3], Step [8100/12942], Loss: 3.3367, Perplexity: 28.1261\n",
      "Epoch [1/3], Step [8200/12942], Loss: 3.2914, Perplexity: 26.8799\n",
      "Epoch [1/3], Step [8300/12942], Loss: 3.3076, Perplexity: 27.3185\n",
      "Epoch [1/3], Step [8400/12942], Loss: 3.5477, Perplexity: 34.73337\n",
      "Epoch [1/3], Step [8500/12942], Loss: 3.4308, Perplexity: 30.9025\n",
      "Epoch [1/3], Step [8600/12942], Loss: 3.5814, Perplexity: 35.9241\n",
      "Epoch [1/3], Step [8700/12942], Loss: 3.5616, Perplexity: 35.21800\n",
      "Epoch [1/3], Step [8800/12942], Loss: 3.0996, Perplexity: 22.1895\n",
      "Epoch [1/3], Step [8900/12942], Loss: 3.3446, Perplexity: 28.3495\n",
      "Epoch [1/3], Step [9000/12942], Loss: 3.4659, Perplexity: 32.0040\n",
      "Epoch [1/3], Step [9100/12942], Loss: 3.3717, Perplexity: 29.1286\n",
      "Epoch [1/3], Step [9200/12942], Loss: 3.5382, Perplexity: 34.4051\n",
      "Epoch [1/3], Step [9300/12942], Loss: 3.5880, Perplexity: 36.1629\n",
      "Epoch [1/3], Step [9400/12942], Loss: 3.2018, Perplexity: 24.5770\n",
      "Epoch [1/3], Step [9500/12942], Loss: 3.5805, Perplexity: 35.8930\n",
      "Epoch [1/3], Step [9600/12942], Loss: 3.4106, Perplexity: 30.2839\n",
      "Epoch [1/3], Step [9700/12942], Loss: 3.8388, Perplexity: 46.4716\n",
      "Epoch [1/3], Step [9800/12942], Loss: 3.3946, Perplexity: 29.8021\n",
      "Epoch [1/3], Step [9900/12942], Loss: 3.2444, Perplexity: 25.64594\n",
      "Epoch [1/3], Step [10000/12942], Loss: 3.4590, Perplexity: 31.7839\n",
      "Epoch [1/3], Step [10100/12942], Loss: 3.3092, Perplexity: 27.3628\n",
      "Epoch [1/3], Step [10200/12942], Loss: 3.8228, Perplexity: 45.7323\n",
      "Epoch [1/3], Step [10300/12942], Loss: 4.1526, Perplexity: 63.5976\n",
      "Epoch [1/3], Step [10400/12942], Loss: 3.5733, Perplexity: 35.6356\n",
      "Epoch [1/3], Step [10500/12942], Loss: 3.7553, Perplexity: 42.74510\n",
      "Epoch [1/3], Step [10600/12942], Loss: 3.7172, Perplexity: 41.1510\n",
      "Epoch [1/3], Step [10700/12942], Loss: 3.6023, Perplexity: 36.6810\n",
      "Epoch [1/3], Step [10800/12942], Loss: 3.4929, Perplexity: 32.88184\n",
      "Epoch [1/3], Step [10900/12942], Loss: 3.2044, Perplexity: 24.64185\n",
      "Epoch [1/3], Step [11000/12942], Loss: 3.4459, Perplexity: 31.3729\n",
      "Epoch [1/3], Step [11100/12942], Loss: 3.2892, Perplexity: 26.8226\n",
      "Epoch [1/3], Step [11200/12942], Loss: 2.9391, Perplexity: 18.89874\n",
      "Epoch [1/3], Step [11300/12942], Loss: 4.2662, Perplexity: 71.2530\n",
      "Epoch [1/3], Step [11400/12942], Loss: 3.1087, Perplexity: 22.3913\n",
      "Epoch [1/3], Step [11500/12942], Loss: 3.0119, Perplexity: 20.32594\n",
      "Epoch [1/3], Step [11600/12942], Loss: 3.2903, Perplexity: 26.8511\n",
      "Epoch [1/3], Step [11700/12942], Loss: 3.3837, Perplexity: 29.4807\n",
      "Epoch [1/3], Step [11800/12942], Loss: 3.1947, Perplexity: 24.40409\n",
      "Epoch [1/3], Step [11900/12942], Loss: 3.2351, Perplexity: 25.40861\n",
      "Epoch [1/3], Step [12000/12942], Loss: 3.2829, Perplexity: 26.6537\n",
      "Epoch [1/3], Step [12100/12942], Loss: 3.9446, Perplexity: 51.6551\n",
      "Epoch [1/3], Step [12200/12942], Loss: 4.0430, Perplexity: 56.9959\n",
      "Epoch [1/3], Step [12300/12942], Loss: 3.2579, Perplexity: 25.9938\n",
      "Epoch [1/3], Step [12400/12942], Loss: 3.3087, Perplexity: 27.3509\n",
      "Epoch [1/3], Step [12500/12942], Loss: 3.3659, Perplexity: 28.9594\n",
      "Epoch [1/3], Step [12600/12942], Loss: 3.5490, Perplexity: 34.7790\n",
      "Epoch [1/3], Step [12700/12942], Loss: 4.5006, Perplexity: 90.0703\n",
      "Epoch [1/3], Step [12800/12942], Loss: 3.2221, Perplexity: 25.0799\n",
      "Epoch [1/3], Step [12900/12942], Loss: 3.0716, Perplexity: 21.5759\n",
      "Epoch [2/3], Step [100/12942], Loss: 3.0312, Perplexity: 20.722163\n",
      "Epoch [2/3], Step [200/12942], Loss: 4.1058, Perplexity: 60.6896\n",
      "Epoch [2/3], Step [300/12942], Loss: 3.0880, Perplexity: 21.9333\n",
      "Epoch [2/3], Step [400/12942], Loss: 3.3079, Perplexity: 27.3265\n",
      "Epoch [2/3], Step [500/12942], Loss: 3.0498, Perplexity: 21.1111\n",
      "Epoch [2/3], Step [600/12942], Loss: 3.2641, Perplexity: 26.1574\n",
      "Epoch [2/3], Step [700/12942], Loss: 3.1627, Perplexity: 23.6353\n",
      "Epoch [2/3], Step [800/12942], Loss: 3.0366, Perplexity: 20.8348\n",
      "Epoch [2/3], Step [900/12942], Loss: 3.0313, Perplexity: 20.7240\n",
      "Epoch [2/3], Step [1000/12942], Loss: 3.2235, Perplexity: 25.1147\n",
      "Epoch [2/3], Step [1100/12942], Loss: 3.1600, Perplexity: 23.5697\n",
      "Epoch [2/3], Step [1200/12942], Loss: 3.5534, Perplexity: 34.93078\n",
      "Epoch [2/3], Step [1300/12942], Loss: 3.4264, Perplexity: 30.76474\n",
      "Epoch [2/3], Step [1400/12942], Loss: 3.0081, Perplexity: 20.24985\n",
      "Epoch [2/3], Step [1500/12942], Loss: 3.0657, Perplexity: 21.4493\n",
      "Epoch [2/3], Step [1600/12942], Loss: 2.9435, Perplexity: 18.9829\n",
      "Epoch [2/3], Step [1700/12942], Loss: 3.1910, Perplexity: 24.3120\n",
      "Epoch [2/3], Step [1800/12942], Loss: 3.0965, Perplexity: 22.1199\n",
      "Epoch [2/3], Step [1900/12942], Loss: 3.0772, Perplexity: 21.6985\n",
      "Epoch [2/3], Step [2000/12942], Loss: 3.0185, Perplexity: 20.4602\n",
      "Epoch [2/3], Step [2100/12942], Loss: 2.9823, Perplexity: 19.7333\n",
      "Epoch [2/3], Step [2200/12942], Loss: 3.5611, Perplexity: 35.2030\n",
      "Epoch [2/3], Step [2300/12942], Loss: 3.1382, Perplexity: 23.0631\n",
      "Epoch [2/3], Step [2400/12942], Loss: 3.0170, Perplexity: 20.4308\n",
      "Epoch [2/3], Step [2500/12942], Loss: 3.2334, Perplexity: 25.3657\n",
      "Epoch [2/3], Step [2600/12942], Loss: 3.3617, Perplexity: 28.8378\n",
      "Epoch [2/3], Step [2700/12942], Loss: 3.0015, Perplexity: 20.1154\n",
      "Epoch [2/3], Step [2800/12942], Loss: 3.3701, Perplexity: 29.0819\n",
      "Epoch [2/3], Step [2900/12942], Loss: 2.8000, Perplexity: 16.4439\n",
      "Epoch [2/3], Step [3000/12942], Loss: 2.8701, Perplexity: 17.6382\n",
      "Epoch [2/3], Step [3100/12942], Loss: 3.2419, Perplexity: 25.5827\n",
      "Epoch [2/3], Step [3200/12942], Loss: 2.8636, Perplexity: 17.5248\n",
      "Epoch [2/3], Step [3300/12942], Loss: 2.9331, Perplexity: 18.78492\n",
      "Epoch [2/3], Step [3400/12942], Loss: 3.0448, Perplexity: 21.0063\n",
      "Epoch [2/3], Step [3500/12942], Loss: 3.2437, Perplexity: 25.6282\n",
      "Epoch [2/3], Step [3600/12942], Loss: 3.4450, Perplexity: 31.3431\n",
      "Epoch [2/3], Step [3700/12942], Loss: 3.0500, Perplexity: 21.1159\n",
      "Epoch [2/3], Step [3800/12942], Loss: 3.1487, Perplexity: 23.3053\n",
      "Epoch [2/3], Step [3900/12942], Loss: 2.9591, Perplexity: 19.2806\n",
      "Epoch [2/3], Step [4000/12942], Loss: 2.9520, Perplexity: 19.1443\n",
      "Epoch [2/3], Step [4100/12942], Loss: 3.3065, Perplexity: 27.2900\n",
      "Epoch [2/3], Step [4200/12942], Loss: 3.0413, Perplexity: 20.9322\n",
      "Epoch [2/3], Step [4300/12942], Loss: 2.9852, Perplexity: 19.7908\n",
      "Epoch [2/3], Step [4400/12942], Loss: 3.4503, Perplexity: 31.5099\n",
      "Epoch [2/3], Step [4500/12942], Loss: 2.8715, Perplexity: 17.6632\n",
      "Epoch [2/3], Step [4600/12942], Loss: 2.6867, Perplexity: 14.6833\n",
      "Epoch [2/3], Step [4700/12942], Loss: 3.0940, Perplexity: 22.0661\n",
      "Epoch [2/3], Step [4800/12942], Loss: 3.0759, Perplexity: 21.6686\n",
      "Epoch [2/3], Step [4900/12942], Loss: 2.9259, Perplexity: 18.6516\n",
      "Epoch [2/3], Step [5000/12942], Loss: 3.0948, Perplexity: 22.0837\n",
      "Epoch [2/3], Step [5100/12942], Loss: 2.9203, Perplexity: 18.5469\n",
      "Epoch [2/3], Step [5200/12942], Loss: 2.7442, Perplexity: 15.5524\n",
      "Epoch [2/3], Step [5300/12942], Loss: 2.9739, Perplexity: 19.5681\n",
      "Epoch [2/3], Step [5400/12942], Loss: 3.0543, Perplexity: 21.2066\n",
      "Epoch [2/3], Step [5462/12942], Loss: 3.0892, Perplexity: 21.9586"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_value_(decoder.parameters(), clip_value)\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "        # Save the weights.\n",
    "        if i_step % save_every == 0:\n",
    "            torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-i-%d.pkl' % epoch))\n",
    "            torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-i-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
